{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3eemdSZOxahh0E0LlvH6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcstllns/DeepLearning_2025/blob/main/PRACTICA_03_Regresion_con_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"darkorange\" size=\"10\"><b>03. Regresión con MLP</b></font>\n",
        "\n",
        "Miguel A. Castellanos"
      ],
      "metadata": {
        "id": "cLhMHf533SB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este cuaderno vamos a construir nuestras primeras redes neuronales usando **pytorch**, vete fijándote en el código y en las explicaciones que se adjuntan porque la mayoría del código se puede reutilizar, de hecho, un buen consejo es preparar tu propio **\"*manual*\"** con las partes de código y explicaciones que creas relevantes.\n",
        "\n",
        "Vamos a empezar por las redes más sencillas, los __perceptrones multicapa__, exactamente iguales que los que hemos estado utilizando en [playground](https://playground.tensorflow.org/).\n",
        "\n",
        "La tarea es identica a la realizada en playground, **predecir unos valores cuantitativos**, pero ahora en vez de ser un sandbox completamente opaco vamos a programar nuestras redes en tiempo real con todo el control.\n",
        "\n",
        "__No te frustres__, a veces escribir código es frustrante porque te da la sensación de que unas veces funciona y otras no. Los ordenadores son deterministas, no tienen opiniones ni les caes mal; si antes te ha funcionado y ahora no es porque hay algo diferente, sigue intentándolo y si ves que no lo consigues consulta con un compañero o con el profesor.\n",
        "\n",
        "En general, los ejercicios siempre están basados en cosas que han sido explicadas en clase, cuando haya un ejercicio que no te salga, relee los materiales y fíjate despacio en el código previo, es posible que la solución la tengas a la vista. Si aún así no encuentras la solución pregunta a tus compañeros y __no dudes en contactar conmigo__."
      ],
      "metadata": {
        "id": "orRyTWuP3WoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero que vamos a hacer es cargar un montón de paquetes y librerías de python que vamos a necesitar para que se calculen las redes. No te preocupes por esta parte, no es necesario entender qué o cómo lo hace, simplemente ejecútala. Lo que hace este código es:\n",
        "\n",
        "Carga los paquetes: numpy, tensorflow2, panda, matplolib, pytorch y sklearn. Son paquetes básicos para el trabajo con datos y los paquetes relacionados con Deep Learning.\n",
        "Para ejecutar un código puedes pinchar en la flecha de la celda o usar Ctr+Enter en el teclado."
      ],
      "metadata": {
        "id": "l9SIsOst4gEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Empezamos trabajando con los datos"
      ],
      "metadata": {
        "id": "5WmTrQEFv_fg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpiUU05jjd0p"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerias que vamos a necesitar\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos unos datos de X e y usando numpy\n",
        "\n",
        "X = np.array(\n",
        "    [258.0, 270.0, 294.0, 320.0, 342.0, 368.0, 396.0, 446.0, 480.0, 586.0]\n",
        ")[:, np.newaxis]\n",
        "\n",
        "y = np.array(\n",
        "    [236.4, 234.4, 252.8, 298.6, 314.2, 342.2, 360.8, 368.0, 391.2, 390.8]\n",
        ")"
      ],
      "metadata": {
        "id": "gODE3EHc4snV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un consejo, las nomenclaturas de las variables son libres, pero se recomienda que sean coherentes, por ejemplo, a veces se les llama X (en mayúscula) e y, otras veces features and labels (o targets).\n",
        "\n",
        "Lo que te recomiendo es que elijas la tuya y escribas tu código siendo coherente con ella, luego cuando tengas que buscar ***bugs*** y errores te harás menos lío.\n",
        "\n",
        "Yo voy a usar X e y en esta práctica."
      ],
      "metadata": {
        "id": "MJ8k4UfD5cl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobamos que se han creado bien\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "jSiFcOK6nOft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fíjate que y es un vector pero X es una matriz de 10 filas y una columna."
      ],
      "metadata": {
        "id": "GK7_L16c6GyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploteamos X e y\n",
        "\n",
        "plt.scatter(X, y)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U3pQp1vZjlDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a utilizar la funcion LinearRegression del paquete sklearn para calcular la recta a esos puntos\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X, y)\n",
        "\n",
        "# create predictions for plotting\n",
        "X_range = np.arange(250, 600, 10)[:, np.newaxis] # de nuevo creamos una matrix nx1 en vez de un vector\n",
        "y_linear = lr.predict(X_range)"
      ],
      "metadata": {
        "id": "2PXViEW7jlF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dibujamos tanto los puntos como la recta\n",
        "\n",
        "plt.scatter(X, y, label=\"Datos\")\n",
        "plt.plot(X_range, y_linear, label=\"Regresión Lineal\", linestyle=\"--\", color=\"orange\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O_HdgKQpjlJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya tenemos los datos y la predicción que se puede hacer con una recta de regresión, ahora vamos a construir una MLP para ver cómo mejoramos la predicción."
      ],
      "metadata": {
        "id": "ERj0iplP7wfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vamos a preparar los datos\n",
        "\n",
        "- Lo primero es hacer la normalización de X e y\n",
        "- Luego se crea un dataset formado por tensores y que sea iterable\n",
        "\n",
        "**Respecto a la normalización:**\n",
        "\n",
        "- En Keras la estrategia es normalizar X y dejar y en su escala, poniendo una función de activación lineal que reescale desde los pesos de la red a la escala original de y\n",
        "- En pytorch no se recomienda, se elimina esa última capa y se deja en la misma escala que los pesos. Posteriormente, cuando se termina de entrenar, se devuelven las predicciones a la misma escala\n",
        "\n",
        "**Respecto a la construcción del dataset:**\n",
        "\n",
        "- Ahora viene una parte extraña, como pytorch tiene que usar tensores y nosotros hemos creados los datos usando numpy hay que convertirlos. Para ello se usa la funcion ***TensorDataset***\n",
        "- Además, es necesario hacer que nuestros datos sean iterables, es decir, que puedan utilizarse uno a uno por la red para entrenarla, esto se hace con la función ***DataLoader***\n",
        "\n",
        "Ambas funciones tienen su complejidad (manejar los datos es más complejo que estimar la red) y poco a poco aprenderemos a sacarles más provecho."
      ],
      "metadata": {
        "id": "o-WcfZqvPgfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparamos los datos\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Normalizamos X e y\n",
        "x_mean, x_std = X.mean(), X.std()\n",
        "y_mean, y_std = y.mean(), y.std()\n",
        "\n",
        "X_norm = (X - x_mean) / x_std\n",
        "y_norm = (y - y_mean) / y_std\n",
        "\n",
        "# Pasamos las variables a tensores\n",
        "tensor_X = torch.Tensor(X_norm) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(y_norm)\n",
        "\n",
        "# Creamos el dataset y el dataloader\n",
        "my_dataset = TensorDataset(tensor_X,tensor_y) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset) # create your dataloader"
      ],
      "metadata": {
        "id": "gYy5YRF5E13F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ahora vamos a definir la red\n",
        "\n",
        "Es una red cutrecilla\n",
        "\n",
        "Definimos la red como una clase, es lo recomendado\n",
        "vamos a crear una red con:\n",
        "- Una entrada con las dimensiones de X\n",
        "- Una única capa con una neurona\n",
        "- Una de salida con una unica neurona sin activación\n"
      ],
      "metadata": {
        "id": "ftxdAn3PQzYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la red como una clase, es lo recomendado\n",
        "# vamos a crear una red con:\n",
        "#   - Una entrada con las dimensiones de X\n",
        "#   - Una capa oculta de 1 neurona\n",
        "#   - Una de salida con una unica neurona sin activación\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, X_nvars):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # Hidden Layer 1\n",
        "            torch.nn.Linear(X_nvars, 1), # Hacemos el sumatorio\n",
        "            torch.nn.ReLU(),              # Aplicamos la función de activacion\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(1, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.layers(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "dws5pLO8jlVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos la red y definimos los Hiper-parámetros"
      ],
      "metadata": {
        "id": "vCoLwxjKRjdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fijamos la semilla a un valor para que los resultados sean identicos\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Ahora fijamos algunos hiper-parámetros\n",
        "\n",
        "# Creamos el modelo MLP\n",
        "model = MLP(X_nvars=1)\n",
        "\n",
        "# Definimos la función loss\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# Elegimos el optimizador\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "MR89kZ2LRnsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ahora hacemos el entrenamiento de la red"
      ],
      "metadata": {
        "id": "WyC7sP-sRsQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Fijamos el número de épocas o iteraciones\n",
        "num_epochs = 200\n",
        "\n",
        "# Una variables donde vamos a ir guardando los valores del loss para ploterarlos\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model = model.train() # se fijan algunas cosas para hacer entrenamiento\n",
        "\n",
        "    # En esta parte se define el batch\n",
        "    # No te preocupes que aún no sabemos qué es\n",
        "    # MUY IMPORTANTE, nunca uses el mismo nombre que tus datos o los sobreescribe\n",
        "    for batch_idx, (features, targets) in enumerate(my_dataloader):\n",
        "\n",
        "        output = model(features)            # Hacemos el forward\n",
        "        loss = loss_fn(output, targets)     # Calculamos el loss\n",
        "\n",
        "        optimizer.zero_grad()        # Ponemos a cero el gradiente\n",
        "        loss.backward()              # Calculamos los gradientes (la derivada del loss)\n",
        "        optimizer.step()             # Cambiamos los pesos de la red\n",
        "\n",
        "        # Cada cierto tiempo vamos a imprimir un poco de información\n",
        "        # para saber qué está pasando\n",
        "        if not batch_idx % 100:\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "                # f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "                f\" | Batch {batch_idx:03d}/{len(my_dataloader):03d}\"\n",
        "                f\" | Train Loss: {loss.item():.2f}\"\n",
        "            )\n",
        "        # añadimos el loss a loss_history\n",
        "    loss_history.append(loss.item())"
      ],
      "metadata": {
        "id": "Rfv-HTIkkZ4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a hacer un plot del loss, a ver qué ha pasado\n",
        "\n",
        "plt.plot(loss_history)"
      ],
      "metadata": {
        "id": "AEa-Nky9SJQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a evaluar el funcionamiento del modelo\n",
        "\n",
        "model.eval() # se fijan parametros del modelo para evaluar\n",
        "\n",
        "# predecimos los valores del rango X_range segun el MLP\n",
        "\n",
        "# Se pasan a un tensor normalizado\n",
        "X_range_norm = (X_range - x_mean) / x_std\n",
        "X_range_norm = torch.tensor(X_range_norm, dtype=torch.float32)\n",
        "\n",
        "# Se meten en el modelo\n",
        "y_mlp_norm = model(X_range_norm)\n",
        "\n",
        "# Ahora se desnormalizan para que estén en la misma escala\n",
        "y_mlp_norm = y_mlp_norm.detach().numpy().astype(np.float64) # dejan de ser un tensor\n",
        "y_mlp = y_mlp_norm * y_std + y_mean # desnormalizan\n"
      ],
      "metadata": {
        "id": "-50YJNpxkZ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a hacer un plot con los resultados\n",
        "\n",
        "# Los datos originales\n",
        "plt.scatter(X, y, label=\"Datos\")\n",
        "\n",
        "# Los datos predichos por la regresion lineal\n",
        "plt.plot(X_range, y_linear, label=\"Regresión lineal\", linestyle=\"--\", color='green')\n",
        "\n",
        "# Los datos predichos por el MLP\n",
        "plt.plot(X_range, y_mlp, label=\"MLP\", color='orange')\n",
        "\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDi34cz6kZ-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Ejercicios\n",
        "\n",
        "Crea un notebook de colab con las soluciones a los ejercicios, hazlo público y sube el enlace al campus virtual\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oimmspJebcAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 01. Ejercicio 1\n",
        "\n",
        "Con los datos de este ejemplo crea una red neuronal que sea capaz de generar un error de cero (es decir, la linea de MLP atraviesa todos los puntos)."
      ],
      "metadata": {
        "id": "zMNbEOAPq_ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 02. Ejercicio 2\n",
        "\n",
        "Usando el código siguiente, construye un MLP que se ajuste razonablemente a los puntos de ese seno. Puedes jugar con la creación de datos.\n"
      ],
      "metadata": {
        "id": "vNwKzc7yrG18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos los datos, en este caso un seno\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "cycles = 2  # numero de periodos\n",
        "n = 100     # numero de datos en x\n",
        "\n",
        "length = 2 * np.pi * cycles\n",
        "\n",
        "x = np.arange(0, length, length / n)\n",
        "y = np.sin(x)\n",
        "\n",
        "plt.plot(x, y, '-')\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "uJ6Cujx4vLOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03. Ejercicio 3\n",
        "\n",
        "Regresión con datos de felicidad\n",
        "\n",
        "Se analizan unos datos obtenido de Kaggle.com sobre la encuesta de felicidad de 2021: [enlace](https://https://www.kaggle.com/datasets/ajaypalsinghlo/world-happiness-report-2021)\n",
        "\n",
        "Una vez limpiados y preparados la base de datos consta de 9 variables predictoras y una variable criterio:\n",
        "\n",
        "**Criterio**: Life.Ladder.\n",
        "\n",
        "**Predictoras**: year, Log.GDP.per.capita, Social.support, Healthy.life.expectancy.at.birth, Freedom.to.make.life.choices, Generosity, Perceptions.of.corruption, Positive.affect, Negative.affect.\n"
      ],
      "metadata": {
        "id": "9NnoUgPLrUat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones para importar y preparar los datos\n",
        "\n",
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/mcstllns/UNIR2024/main/data-happiness.csv'\n",
        "data  = pd.read_csv(url)\n",
        "print(data.keys())\n",
        "data.head()\n",
        "\n",
        "# El fichero tiene datos perdidos y hay que eliminar las filas\n",
        "data = data.dropna()\n",
        "\n",
        "# Creamos conjuntos X e y\n",
        "X = data.drop('Life.Ladder', axis=1)\n",
        "y = data['Life.Ladder']\n",
        "\n",
        "print(X.head())\n",
        "print(y.head())\n"
      ],
      "metadata": {
        "id": "gDBHKx3WRNdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparamos los datos\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Normalizamos X e y\n",
        "x_mean, x_std = X.mean(), X.std()\n",
        "y_mean, y_std = y.mean(), y.std()\n",
        "\n",
        "X_norm = (X - x_mean) / x_std\n",
        "y_norm = (y - y_mean) / y_std\n",
        "\n",
        "# Pasamos las variables a tensores\n",
        "# Ojo, como son dataframes de pandas la sintaxis es un poco diferente\n",
        "\n",
        "tensor_X = torch.from_numpy(X_norm.values)\n",
        "tensor_y = torch.from_numpy(y_norm.values)\n",
        "\n",
        "# Creamos el dataset y el dataloader\n",
        "my_dataset = TensorDataset(tensor_X,tensor_y) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset) # create your dataloader"
      ],
      "metadata": {
        "id": "xj5zFAwBsc-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor_X.shape)\n",
        "print(tensor_y.shape)"
      ],
      "metadata": {
        "id": "uPDtqU8askX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora ya se puede calcular la red\n",
        "\n",
        "Ojo: NO intentes hacer un plot de X, y porque ahora X tiene 9 variables\n",
        "\n",
        "El mejor modelo calculado con estadística convencional (modelo lineal) da un **MSE de 0.235**\n",
        "\n",
        "**Supera el MSE de la regresión múltiple**\n"
      ],
      "metadata": {
        "id": "6QTgXumvuF1A"
      }
    }
  ]
}